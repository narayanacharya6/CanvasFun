{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example-Deu-Eng-MT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPIwLm8nsmlEppeT0yj5CIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narayanacharya6/CanvasFun/blob/master/Example_Deu_Eng_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II8fnh8yJQGe",
        "colab_type": "text"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-HUw7eHiqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09b1b2e6-7035-46a3-88a7-6e06d15ac956"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdWA8_lSH25O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34679775-b071-48ea-8a55-23e7a77a536c"
      },
      "source": [
        "%cd 'drive/My Drive/Projects-Scratchpad/NLP/German-To-English-MT'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Projects-Scratchpad/NLP/German-To-English-MT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71B2UOJ1JVz_",
        "colab_type": "text"
      },
      "source": [
        "### Get data if not done already!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUpbgMPFH9Fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO448uWSITAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dcea55a-16cc-4402-837e-0b701eba5892"
      },
      "source": [
        "%cd data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Projects-Scratchpad/NLP/German-To-English-MT/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CC9kbQPIgJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ee6cbb1b-9f9b-48e6-a944-4df90a286096"
      },
      "source": [
        "!wget http://www.manythings.org/anki/deu-eng.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-09 22:47:07--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:3037::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7747747 (7.4M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "deu-eng.zip         100%[===================>]   7.39M  4.47MB/s    in 1.7s    \n",
            "\n",
            "2020-02-09 22:47:09 (4.47 MB/s) - ‘deu-eng.zip’ saved [7747747/7747747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78ARz-8fJ_Ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ccb9014d-a02b-4d08-98b2-3558e5f2d4b4"
      },
      "source": [
        "!unzip deu-eng.zip"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLjVyB36Iqhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d830b524-e1df-45c8-dd61-25675f362328"
      },
      "source": [
        "!ls -lrt\n",
        "%cd .."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 38797\n",
            "-rw------- 1 root root  7747747 Jan 11 14:49 deu-eng.zip\n",
            "-rw------- 1 root root 31978057 Jan 11 23:49 deu.txt\n",
            "-rw------- 1 root root     1441 Jan 11 23:49 _about.txt\n",
            "/content/drive/My Drive/Projects-Scratchpad/NLP/German-To-English-MT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUqn4EIQIyES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "af9ad136-151f-4020-f126-83554f2c8b14"
      },
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Feb  5 18:37 sample_data\n",
            "drwx------ 4 root root 4096 Feb  9 23:17 drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umjomEBBJfeJ",
        "colab_type": "text"
      },
      "source": [
        "### Upgrade to TensorFlow 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlpWRqrKQLhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "55f17ba1-8fc4-4342-fbc6-b24dad78a9ba"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeW6hd05QZO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8515d28-576d-479f-e2ce-17dca70179a8"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed google-auth-1.11.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsGw64hWRLKz",
        "colab_type": "text"
      },
      "source": [
        "### Lets get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8HpKb6OJiy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d7209fd-d575-4a15-d556-11fbfc6806c7"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILbnHgwgJpyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "  # open the file\n",
        "  file = open(filename, mode='rt', encoding='utf-8')\n",
        "\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "  sents = text.strip().split('\\n')\n",
        "  sents = [i.split('\\t') for i in sents]\n",
        "  return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QubMyF0RJ2ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"data/deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sXaQ7PBKs9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "1b3f7b61-b4ee-4ac6-a7a7-ffd0f699a9ee"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Hi.', 'Hallo!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi.', 'Grüß Gott!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ['Run!', 'Lauf!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)'],\n",
              "       ...,\n",
              "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
              "        'Wenn jemand Fremdes dir sagt, dass du dich wie ein Muttersprachler anhörst, bedeutet das wahrscheinlich: Er hat etwas an deinem Sprechen bemerkt, dass dich als Nicht-Muttersprachler verraten hat. Mit anderen Worten: Du hörst dich nicht wirklich wie ein Muttersprachler an.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #3807493 (Tickler)'],\n",
              "       ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.',\n",
              "        'Es ist wohl unmöglich, einen vollkommen fehlerfreien Korpus zu erreichen\\xa0— das liegt in der Natur eines solchen Gemeinschaftsprojekts. Doch wenn wir unsere Mitglieder dazu bringen können, nicht mit Sprachen herumzuexperimentieren, die sie gerade lernen, sondern Sätze in ihrer eigenen Muttersprache beizutragen, dann gelingt es uns vielleicht, die Zahl der Fehler klein zu halten.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2024159 (CK) & #2174272 (Pfirsichbaeumchen)'],\n",
              "       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.',\n",
              "        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7729416 (Pfirsichbaeumchen)']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIkp5ZBHRaVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take limited rows depending upon compute!\n",
        "# deu_eng = deu_eng[:50000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLmLWyfLJ_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove attribution field\n",
        "deu_eng = deu_eng[:, :2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_I9wLbK1R_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "4b8ef08b-b242-44b0-8b8d-d59cd47bd18d"
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Hi', 'Hallo'],\n",
              "       ['Hi', 'Grüß Gott'],\n",
              "       ['Run', 'Lauf'],\n",
              "       ...,\n",
              "       ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker',\n",
              "        'Wenn jemand Fremdes dir sagt dass du dich wie ein Muttersprachler anhörst bedeutet das wahrscheinlich Er hat etwas an deinem Sprechen bemerkt dass dich als NichtMuttersprachler verraten hat Mit anderen Worten Du hörst dich nicht wirklich wie ein Muttersprachler an'],\n",
              "       ['It may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort However if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
              "        'Es ist wohl unmöglich einen vollkommen fehlerfreien Korpus zu erreichen\\xa0— das liegt in der Natur eines solchen Gemeinschaftsprojekts Doch wenn wir unsere Mitglieder dazu bringen können nicht mit Sprachen herumzuexperimentieren die sie gerade lernen sondern Sätze in ihrer eigenen Muttersprache beizutragen dann gelingt es uns vielleicht die Zahl der Fehler klein zu halten'],\n",
              "       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people and out of the few hundred that there are but a dozen or less whom he knows intimately and out of the dozen one or two friends at most it will easily be seen when we remember the number of millions who inhabit this world that probably since the earth was created the right man has never yet met the right woman',\n",
              "        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt wenn man jedoch in Betracht zieht dass ein Mensch nur Gelegenheit hat mit ein paar hundert anderen bekannt zu sein von denen ihm nur ein Dutzend oder weniger nahesteht darunter höchstens ein oder zwei Freunde dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5qnhxzCLCfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "bc31b34e-27d7-4d84-d3f2-e71cd324862c"
      },
      "source": [
        "# convert text to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['hi', 'hallo'],\n",
              "       ['hi', 'grüß gott'],\n",
              "       ['run', 'lauf'],\n",
              "       ...,\n",
              "       ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker',\n",
              "        'wenn jemand fremdes dir sagt dass du dich wie ein muttersprachler anhörst bedeutet das wahrscheinlich er hat etwas an deinem sprechen bemerkt dass dich als nichtmuttersprachler verraten hat mit anderen worten du hörst dich nicht wirklich wie ein muttersprachler an'],\n",
              "       ['it may be impossible to get a completely errorfree corpus due to the nature of this kind of collaborative effort however if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning we might be able to minimize errors',\n",
              "        'es ist wohl unmöglich einen vollkommen fehlerfreien korpus zu erreichen\\xa0— das liegt in der natur eines solchen gemeinschaftsprojekts doch wenn wir unsere mitglieder dazu bringen können nicht mit sprachen herumzuexperimentieren die sie gerade lernen sondern sätze in ihrer eigenen muttersprache beizutragen dann gelingt es uns vielleicht die zahl der fehler klein zu halten'],\n",
              "       ['doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people and out of the few hundred that there are but a dozen or less whom he knows intimately and out of the dozen one or two friends at most it will easily be seen when we remember the number of millions who inhabit this world that probably since the earth was created the right man has never yet met the right woman',\n",
              "        'ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht dass ein mensch nur gelegenheit hat mit ein paar hundert anderen bekannt zu sein von denen ihm nur ein dutzend oder weniger nahesteht darunter höchstens ein oder zwei freunde dann erahnt man eingedenk der millionen einwohner dieser welt\\xa0leicht dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz957srbLeP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ed340f77-cf66-43c3-d536-e825007ff4ba"
      },
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "      eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "      deu_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAekElEQVR4nO3df7BU5Z3n8fcnoPHHqIBm7yg4gVlZ\nU0ZHI4wwlVSGDRNEzQZn1jgYd0HXkmyJRmfcWnFqqnD9MUWmkhidZJyQSAQrEZHoyEaUsMRbM6kN\nKKCjouN6g6hQKOoFDJpocL77x3n6cGj69u0Lt3/ez6uqq/t8z49+Tt/T99vnPM95HkUEZmZmAB9p\ndgHMzKx1OCmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBQ6gKR7JN3a7HKYWftzUjAzs5yTgpmZ\n5ZwU2pCkT0naKOlXku4HjijM+4KkpyXtkvR/Jf1BYV5IOqUw7ctO1hYknSTpx5LelPSypK+m+E2S\nlklakr4PmyRNLKx3tqSn0rwHJN3vY746J4U2I+lw4B+Be4FRwAPAf07zPgUsAr4CHA98F1gh6aPN\nKa3ZoZP0EeB/A/8CjAamAtdJOjct8kVgKTACWAF8O613OPAQcA/Zd+U+4E8bWfZ25KTQfiYDhwHf\niojfRsRy4Mk0bw7w3YhYFxEfRsRi4P20jlm7+kPgYxFxc0R8EBGbge8BM9P8n0fEyoj4kOzH0pkp\nPhkYDtyZvisPAk80uvDtZnizC2ADdhKwLfbvyfCV9PxxYLakawrzDk/rmLWrjwMnSdpViA0D/pns\n2H+9EH8POELScCp/V16rd2Hbnc8U2s92YLQkFWK/l55fA26LiBGFx1ERcV+a/x5wVGG9321Aec0O\n1WvAy2XH9TERcX4/61X6rpxcv2J2BieF9vMLYC/wVUmHSfoz4Jw073vAf5c0SZmjJV0g6Zg0/2ng\ny5KGSZoO/HHji282YE8Av5J0g6Qj0/F7uqQ/7Ge9XwAfAldLGi5pBvu+K9YHJ4U2ExEfAH8GXAb0\nAn8OPJjmrQeuJKto2wn0pOVKrgX+E7ALuJSswtqspaW6gi8AZwEvA28B3weO62e90nflCrJj/r8A\nPyGrZ7M+yIPsmNlQIWkd8A8R8YNml6VV+UzBzDqWpD+W9Lvp8tFs4A+Ax5pdrlbm1kdm1slOBZYB\nRwObgYsiYntzi9TafPnIzMxyvnxkZma5tr18dMIJJ8TYsWPz6XfffZejjz66eQU6CO1W5k4r74YN\nG96KiI81sEiHpPyYh/b7m9SLP4fMoBzzEdGWjwkTJkTR448/Hu2m3crcaeUF1kcLHMu1PsqP+Vr2\ncajw55AZjGPel4/MzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws\n17bdXByKsfMe2W96y4ILmlQSa7KxknYAOyLidABJo4D7gbHAFuDiiNiZhnS8AzifbFjTyyJiY1pn\nNvDXaZu3RsTiFJ8A3AMcCawEro2I6Os9BnXHfIzbQfKZgg1lbwHTy2LzgDURMR5Yk6YBzgPGp8cc\n4C7Ik8h8YBLZUI/zJY1M69xFNhJeab3p/byHWdPVlBQk/YWkTZKek3SfpCMkjZO0TlKPpPslHZ6W\n/Wia7knzxxa2c2OKvyjp3EJ8eor1SPIXxBplD9mQpkUzgMXp9WLgwkJ8SepCZi0wQtKJwLnA6ojo\nTb/2VwPT07xjI2Jt6nNmSdm2Kr2HWdP1e/lI0mjgq8BpEfFrScuAmWSn0bdHxFJJ/0A2Dupd6Xln\nRJwiaSbwNeDPJZ2W1vskcBLwfyT9h/Q23wE+D2wFnpS0IiKeH9Q9NatNV+wbhOV1oCu9Hg28Vlhu\na4pVi2+tEK/2HgeQNIfszISuri66u7v3m79nz54DYgDXn7F3v+lKy3SSvj6HoWYwPoda6xSGA0dK\n+i1wFLAd+Bzw5TR/MXATWVKYkV4DLAe+na7HzgCWRsT7wMuSeshOtwF6ImIzgKSlaVknBWuqdP2/\nrqNQ9fceEbEQWAgwceLEmDJlyn7zu7u7KY8BXFZep3Dpgct0kr4+h6FmMD6Hfi8fRcQ24OvAq2TJ\nYDewAdgVEaWfI8VfQfkvpzR/N3A8A/+lZdYMb6RLP6TnHSm+DTi5sNyYFKsWH1MhXu09zJqulstH\nI8l+uY8DdgEPcGDlXENUO5UeyGlTq5xat9sp7xAp7wpgNrAgPT9ciF+dzmQnAbsjYrukVcDfFCqX\npwE3RkSvpHckTQbWAbOAv+vnPcyarpbLR38CvBwRbwJIehD4NFlF2/B0NlD8FVT65bRV0nDgOOBt\n+v5FRZX4fqqdSg/ktKlVTq3b7ZS3A8s7DvgFcIKkrWStiBYAyyRdAbwCXJyWXUlWj9ZD1iT1coD0\nz/8W4Mm03M0RUaq8vop9TVIfTQ+qvIdZ09WSFF4FJks6Cvg1MBVYDzwOXAQs5cBfVLPJvmwXAT9L\n101XAD+S9E2yiubxwBOAgPGSxpElg5nsq6swq6eXI2JihfjU8kBqQTS30kYiYhGwqEJ8PXB6hfjb\nld7DrBX0mxQiYp2k5cBGYC/wFNmv9UeApZJuTbG70yp3A/emiuResn/yRMSm1HLp+bSduRHxIYCk\nq4FVwDBgUURsGrxdNDOzWtXU+igi5pOdWhdtZl/roeKyvwG+1Md2bgNuqxBfSXZ6bmZmTeQ7ms3M\nLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkp\nmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5WoaZKfdjS0bk9nMzCrr90xB0qmSni483pF0naRRklZL\neik9j0zLS9KdknokPSPp7MK2ZqflX5I0uxCfIOnZtM6dklSf3TUzs2r6TQoR8WJEnBURZwETgPeA\nh4B5wJqIGA+sSdMA5wHj02MOcBeApFFkQ3pOIhvGc34pkaRlriysN31Q9s7MzAZkoHUKU4FfRsQr\nwAxgcYovBi5Mr2cASyKzFhgh6UTgXGB1RPRGxE5gNTA9zTs2ItZGRABLCtsyM7MGGmidwkzgvvS6\nKyK2p9evA13p9WjgtcI6W1OsWnxrhfgBJM0hO/ugq6uL7u7ufN6ePXv2my66/oy9VXeqr/XqrVqZ\nW5HLa9b5ak4Kkg4HvgjcWD4vIkJSDGbBKomIhcBCgIkTJ8aUKVPyed3d3RSniy7rp6J5y6WV16u3\namVuRS6vWecbyOWj84CNEfFGmn4jXfohPe9I8W3AyYX1xqRYtfiYCnEzM2uwgSSFS9h36QhgBVBq\nQTQbeLgQn5VaIU0GdqfLTKuAaZJGpgrmacCqNO8dSZNTq6NZhW2ZmVkD1XT5SNLRwOeBrxTCC4Bl\nkq4AXgEuTvGVwPlAD1lLpcsBIqJX0i3Ak2m5myOiN72+CrgHOBJ4ND3MzKzBakoKEfEucHxZ7G2y\n1kjlywYwt4/tLAIWVYivB06vpSxmZlY/7ubCzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzCqQ9BeSNkl6\nTtJ9ko6QNE7SutRx4/3phk4kfTRN96T5YwvbuTHFX5R0biE+PcV6JM07sARmzeGkYFZG0mjgq8DE\niDgdGEbWxcvXgNsj4hRgJ3BFWuUKYGeK356WQ9Jpab1PknXy+PeShkkaBnyH7IbQ04BL0rJmTeek\nYFbZcOBIScOBo4DtwOeA5Wl+eSeQpc4hlwNT042YM4ClEfF+RLxMdu/OOenRExGbI+IDYGla1qzp\nhsQgO2YDERHbJH0deBX4NfBTYAOwKyJKvSsWO27MO3uMiL2SdpPd1zMaWFvYdHGd8s4hJ1UqS7VO\nIKHvTv/KO4Hs9I4B3flhZjA+BycFszKpG5YZwDhgF/AATRrjo1onkNB3p3/lnUA2q9PHRnHnh5nB\n+Bx8+cjsQH8CvBwRb0bEb4EHgU+TjQ1S+iFV7Lgx7+wxzT8OeJuBdw5p1nROCmYHehWYLOmoVDcw\nFXgeeBy4KC1T3glkqXPIi4Cfpe5eVgAzU+ukcWSjCj5B1v/X+NSa6XCyyugVDdgvs3758pFZmYhY\nJ2k5sBHYCzxFdgnnEWCppFtT7O60yt3AvZJ6gF6yf/JExCZJy8gSyl5gbkR8CCDparKeg4cBiyJi\nU6P2z6waJwWzCiJiPtmY4kWbyVoOlS/7G+BLfWznNuC2CvGVZD0Km7UUXz4yM7Ock4KZmeWcFMzM\nLFdTUpA0QtJySf8q6QVJfyRplKTVkl5KzyPTspJ0Z+rT5RlJZxe2Mzst/5Kk2YX4BEnPpnXuTC0+\nzMyswWo9U7gDeCwiPgGcCbwAzAPWRMR4YE2ahqw/l/HpMQe4C0DSKLKKu0lklXXzS4kkLXNlYb2m\n3ChkZjbU9ZsUJB0HfJbU/C4iPoiIXezf30t5PzBLIrOW7IafE4FzgdUR0RsRO4HVwPQ079iIWJva\ndi8pbMvMzBqoliap44A3gR9IOpOsD5hrga6I2J6WeR3oSq/zfmCSUn8v1eJbK8QPUK0fmGp9fpT3\nA1OuWX2mtFt/LS6vWeerJSkMB84Grkk39dzBvktFAERESIp6FLDsffrsB6Zanx/l/cCUa1a/MO3W\nX4vLa9b5aqlT2ApsjYh1aXo5WZJ4I136IT3vSPMH2t/LtvS6PG5mZg3Wb1KIiNeB1ySdmkKlfmCK\n/b2U9wMzK7VCmgzsTpeZVgHTJI1MFczTgFVp3juSJqdWR7MK2zIzswaqtZuLa4Afps67NgOXkyWU\nZZKuAF4BLk7LrgTOJxtQ5L20LBHRK+kWss7AAG6OiN70+irgHuBI4NH0MDOzBqspKUTE08DECrOm\nVlg2gLl9bGcRsKhCfD1wei1lMTOz+vEdzWZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkp\nmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMcjUlBUlb\nJD0r6WlJ61NslKTVkl5KzyNTXJLulNQj6RlJZxe2Mzst/5Kk2YX4hLT9nrSuBntHzcysfwM5U/iP\nEXFWRJRGYJsHrImI8cCaNA1wHjA+PeYAd0GWRID5wCTgHGB+KZGkZa4srDf9oPfIzMwO2qFcPpoB\nLE6vFwMXFuJLIrMWGCHpROBcYHVE9EbETmA1MD3NOzYi1qahPJcUtmVmZg1U0xjNQAA/lRTAdyNi\nIdAVEdvT/NeBrvR6NPBaYd2tKVYtvrVC/ACS5pCdfdDV1UV3d3c+b8+ePftNF11/xt6qO9fXevVW\nrcytyOU163y1JoXPRMQ2Sf8OWC3pX4szIyJSwqirlIwWAkycODGmTJmSz+vu7qY4XXTZvEeqbnfL\npZXXq7dqZW5FQ6m8kkYA3wdOJ/tR9N+AF4H7gbHAFuDiiNiZ6sDuAM4H3gMui4iNaTuzgb9Om701\nIhan+ATgHuBIYCVwbTpTNmuqmi4fRcS29LwDeIisTuCNdOmH9LwjLb4NOLmw+pgUqxYfUyFu1kx3\nAI9FxCeAM4EXcD2aDQH9JgVJR0s6pvQamAY8B6wASi2IZgMPp9crgFmpFdJkYHe6zLQKmCZpZPpi\nTANWpXnvSJqcfnHNKmzLrOEkHQd8FrgbICI+iIhduB7NhoBaLh91AQ+lVqLDgR9FxGOSngSWSboC\neAW4OC2/kuw0uofsVPpygIjolXQL8GRa7uaI6E2vr2LfqfSj6WHWLOOAN4EfSDoT2ABcS4vVo0Hf\n9Sbl9WidXrfi+qPMYHwO/SaFiNhMdvpcHn8bmFohHsDcPra1CFhUIb6e7NqtWSsYDpwNXBMR6yTd\nwb5LRUBr1KNB3/Um5fVozao3a5R2q++ql8H4HHxHs9mBtgJbI2Jdml5OliRcj2Ydz0nBrExEvA68\nJunUFJoKPI/r0WwIqLVJqtlQcw3wQ0mHA5vJ6sY+guvRrMM5KZhVEBFPAxMrzHI9mnU0Xz4yM7Oc\nk4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBm\nZrmak4KkYZKekvSTND1O0jpJPZLuT71JIumjabonzR9b2MaNKf6ipHML8ekp1iNpXvl7m5lZYwzk\nTOFassHLS74G3B4RpwA7gStS/ApgZ4rfnpZD0mnATOCTZIOU/31KNMOA75ANfn4acEla1szMGqym\npCBpDHAB8P00LeBzZCNSwYGDmJcGN18OTE3LzwCWRsT7EfEyWd/z56RHT0RsjogPgKVpWTMza7Ba\nx1P4FvA/gWPS9PHArogojQ5eHHg8H6w8IvZK2p2WHw2sLWyzuE754OaTKhWi2iDm1QasLh/EvFyz\nBvxut8HGXV6zztdvUpD0BWBHRGyQNKX+RepbtUHMqw1YXT6IeblmDWreboONu7xmna+WM4VPA1+U\ndD5wBHAscAcwQtLwdLZQHHi8NFj5VknDgeOAt+l7EHOqxM3MrIH6TQoRcSNwI0A6U/gfEXGppAeA\ni8jqAMoHMZ8N/CLN/1lEhKQVwI8kfRM4CRgPPAEIGC9pHFkymAl8edD20KzDje3nTNhsIA5ljOYb\ngKWSbgWeAu5O8buBeyX1AL1k/+SJiE2SlgHPA3uBuRHxIYCkq4FVwDBgUURsOoRymZnZQRpQUoiI\nbqA7vd5M1nKofJnfAF/qY/3bgNsqxFcCKwdSFjMzG3y+o9nMzHJOCmZmlnNSMDOznJOCmZnlnBTM\nzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjDrg4egtaHIScGsbx6C1oacQ+kl1axjFYag\nvQ34y8IQtKVu3RcDNwF3kQ0fe1OKLwe+XT4ELfBy6jm41IlkT+pUEkmlIWifr9f+VOpee8uCC+r1\ndtbGnBTMKmv5IWghG3L0+jM+HOCuZTppqFIPvZoZjM/BScGsTLsMQQvZP/Zv/Pzdg9p2s4ahrQcP\nvZoZjM/BScHsQB6C1oasfiuaJR0h6QlJ/yJpk6T/leJuiWEdKSJujIgxETGWrKL4ZxFxKfA42RCz\nUHkIWigMQZviM9N3Yhz7hqB9kjQEbfrezEzLmjVdLa2P3gc+FxFnAmcB0yVNxi0xbOi5gazSuYes\nzqA4BO3xKf6XwDzIhqAFSkPQPkYagjadaZSGoH0BWOYhaK1V9Hv5KP3i2ZMmD0uPoI1bYpjVykPQ\n2lBTU51C+jW/ATiF7Ff9L2mxlhjVat2vP2NvxXhJs1ottFuLCZfXrPPVlBQi4kPgLEkjgIeAT9S1\nVH2Xo8+WGNVq3S+r0Ea7qFmtMNqtxYTLa9b5BnRHc0TsIqts+yNSS4w0q1JLDGpsiVGthYaZmTVQ\nLa2PPpbOEJB0JPB5ssoxt8QwM+swtVw+OhFYnOoVPkLWUuInkp4Hlkq6FXiK/Vti3JsqknvJ/skT\nEZsklVpi7CW1xACQVGqJMQxY5JYYZmbNUUvro2eAT1WIuyWGmVmHcS+pZmaWc1IwM7Ock4KZmeWc\nFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMz\nyzkpmJlZzknBzMxytQzHebKkxyU9L2mTpGtTfJSk1ZJeSs8jU1yS7pTUI+kZSWcXtjU7Lf+SpNmF\n+ARJz6Z17pSkeuysmZlVV8twnHuB6yNio6RjgA2SVgOXAWsiYoGkecA84AbgPLLxl8cDk4C7gEmS\nRgHzgYlApO2siIidaZkrgXVkI7BNBx4dvN2sbuy8Rw6IbVlwQaPe3sysZfR7phAR2yNiY3r9K+AF\nYDQwA1icFlsMXJhezwCWRGYtMELSicC5wOqI6E2JYDUwPc07NiLWRkQASwrbMjOzBhpQnYKksWTj\nNa8DuiJie5r1OtCVXo8GXiustjXFqsW3VoibmVmD1XL5CABJvwP8GLguIt4pXvaPiJAUdShfeRnm\nAHMAurq66O7uzuft2bNnv+mi68/YO+D36mtbg6lamVuRy2vW+WpKCpIOI0sIP4yIB1P4DUknRsT2\ndAloR4pvA04urD4mxbYBU8ri3Sk+psLyB4iIhcBCgIkTJ8aUKfs2193dTXG66LIKdQb92XJp5W0N\npmplbkUur1nnq6X1kYC7gRci4puFWSuAUgui2cDDhfis1AppMrA7XWZaBUyTNDK1VJoGrErz3pE0\nOb3XrMK2zMysgWo5U/g08F+BZyU9nWJ/BSwAlkm6AngFuDjNWwmcD/QA7wGXA0REr6RbgCfTcjdH\nRG96fRVwD3AkWaujhrU8MjOzffpNChHxc6Cv+wamVlg+gLl9bGsRsKhCfD1wen9lMTOz+vIdzWZm\nlnNSMCvju/htKHNSMDtQ6S7+04DJwFxJp5Hdtb8mIsYDa9I07H8X/xyyO/Qp3MU/CTgHmF9KJOy7\ni7+03vQG7JdZv5wUzMr4Ln4bymq+ec1sKGr2XfzVbtiE7Aa968/4cGA7lXTSjX2+UTEzGJ+Dk4JZ\nH1rhLv5qN2xC9o/9Gz9/96C23YgbNBvFNypmBuNz6LikUKnHU7OBapW7+M0azXUKZmV8F78NZR13\npmA2CHwXvw1ZTgpmZXwXvw1lvnxkZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7NcLcNxLpK0\nQ9JzhZi7EDYz60C1nCncw4Hd+roLYTOzDlTLcJz/lHqKLJrBvj5dFpP153IDhS6EgbWSSl0ITyF1\nIQwgqdSFcDepC+EUL3Uh3PS7O8v7UNqy4IImlcTMrHEOtk6h4V0Im5lZ/R1yNxeN6kIYqvctX+pH\n/Poz9tblvevRV3u79QHv8pp1voNNCk3pQrha3/KlfsQvq1PX2fXoe77d+oB3ec0638EmhVIXwgs4\nsAvhqyUtJatU3p0SxyrgbwqVy9OAG1Mvku+k7obXkXUh/HcHWSYzGwDXm1kl/SYFSfeR/co/QdJW\nslZE7kLYzKwD1dL66JI+ZrkLYTOzDuM7ms3MLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNS\nMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs9whj9E8VJSPUgUe\nqcrMOo+TgpkBHp7TMi2TFCRNB+4AhgHfj4gFTS5Sv/wlskPRjse8db6WqFOQNAz4DnAecBpwiaTT\nmlsqs/rxMW+tqlXOFM4BeiJiM4CkpcAM4PmmlmqAKtU7lPPZhCUtf8z7eB6aWiUpjAZeK0xvBSaV\nLyRpDjAnTe6R9GJh9gnAW3Ur4SDR1/abbIsyF3RaeT/eqIJUMBjHPDT5b1J2PDdTux2b9XLIx3yr\nJIWaRMRCYGGleZLWR8TEBhfpkLRbmV3exqt2zENn7ONg8OeQGYzPoSXqFIBtwMmF6TEpZtapfMxb\nS2qVpPAkMF7SOEmHAzOBFU0uk1k9+Zi3ltQSl48iYq+kq4FVZM3zFkXEpgFups9T7BbWbmV2eQfJ\nIB3z0ML72GD+HDKH/DkoIgajIGZm1gFa5fKRmZm1ACcFMzPLdURSkDRd0ouSeiTNa3Z5ykk6WdLj\nkp6XtEnStSl+k6Rtkp5Oj/ObXdYSSVskPZvKtT7FRklaLeml9Dyy2eUEkHRq4TN8WtI7kq5r5c93\nMLT6cV9P7XR8DiZJiyTtkPRcIVZxv5W5Mx0fz0g6u6b3aPc6hdRdwP8DPk92A9CTwCUR0TJ3hko6\nETgxIjZKOgbYAFwIXAzsiYivN7WAFUjaAkyMiLcKsb8FeiNiQfonNDIibmhWGStJx8M2shvBLqdF\nP99D1Q7HfT216/F5qCR9FtgDLImI01Os4n6nH0HXAOeTfR/uiIgDbpAs1wlnCnl3ARHxAVDqLqBl\nRMT2iNiYXv8KeIHsjtZ2MwNYnF4vJktsrWYq8MuIeKXZBamzlj/um6Adjs9DEhH/BPSWhfva7xlk\nySMiYi0wIv1AraoTkkKl7gJa9h+upLHAp4B1KXR1OrVb1GKnuwH8VNKG1NUCQFdEbE+vXwe6mlO0\nqmYC9xWmW/XzPVRtddzXQbsen/XQ134f1DHSCUmhbUj6HeDHwHUR8Q5wF/DvgbOA7cA3mli8cp+J\niLPJevGcm05bc5Fdd2ypa4/pJrAvAg+kUCt/vnZo2u74bITB2O9OSApt0V2ApMPIEsIPI+JBgIh4\nIyI+jIh/A75HdkmgJUTEtvS8A3iIrGxvlE4/0/OO5pWwovOAjRHxBrT25zsI2uK4r5c2PT7rpa/9\nPqhjpBOSQst3FyBJwN3ACxHxzUK8eH3vT4HnytdtBklHpwpxJB0NTCMr2wpgdlpsNvBwc0rYp0so\nXDpq1c93kLT8cV8vbXx81ktf+70CmJVaIU0GdhcuM/Wp7VsfAaRa9m+xr7uA25pcpP1I+gzwz8Cz\nwL+l8F+R/RM7i+x0bwvwlVr+aPUm6ffJfn1B1hXKjyLiNknHA8uA3wNeAS6OiPJKr6ZI/xxeBX4/\nInan2L204Oc7WFr9uK+Xdjw+B4uk+4ApZF1kvwHMB/6RCvudfox+G5gOvAdcHhHr+32PTkgKZmY2\nODrh8pGZmQ0SJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeX+P89BZldcVqf9AAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTEvR_C3Lorh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8nQSFKgLrvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dba5f7bd-4ad6-4879-f35e-66c346e66060"
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 16380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df5BKOGMLu3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c280c6b-d602-460d-aed9-fec2356aabf8"
      },
      "source": [
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 35442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTHO0YvsLzhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  # integer encode sequences\n",
        "  seq = tokenizer.texts_to_sequences(lines)\n",
        "  # pad sequences with 0 values\n",
        "  seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrnN3f84L4Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K5jOxBnL8hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtnJfHLkMB2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(units))\n",
        "  model.add(RepeatVector(out_timesteps))\n",
        "  model.add(LSTM(units, return_sequences=True))\n",
        "  model.add(Dense(out_vocab, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALgD7b8CMF0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model compilation\n",
        "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAzHMQ6gMJTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAHnZ90MPzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a75fab4-cd4d-4fe1-a014-b21e0a7e5b03"
      },
      "source": [
        "filename = 'model.h1.09_02_19.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2, callbacks=[checkpoint], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 130927 samples, validate on 32732 samples\n",
            "Epoch 1/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 4.8916\n",
            "Epoch 00001: val_loss improved from inf to 4.55463, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 53s 409us/sample - loss: 4.8905 - val_loss: 4.5546\n",
            "Epoch 2/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 4.2978\n",
            "Epoch 00002: val_loss improved from 4.55463 to 4.09294, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 290us/sample - loss: 4.2972 - val_loss: 4.0929\n",
            "Epoch 3/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 3.8670\n",
            "Epoch 00003: val_loss improved from 4.09294 to 3.70155, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 288us/sample - loss: 3.8662 - val_loss: 3.7015\n",
            "Epoch 4/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 3.4624\n",
            "Epoch 00004: val_loss improved from 3.70155 to 3.37390, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 289us/sample - loss: 3.4622 - val_loss: 3.3739\n",
            "Epoch 5/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 3.1030\n",
            "Epoch 00005: val_loss improved from 3.37390 to 3.09057, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 293us/sample - loss: 3.1027 - val_loss: 3.0906\n",
            "Epoch 6/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 2.8094\n",
            "Epoch 00006: val_loss improved from 3.09057 to 2.86680, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 290us/sample - loss: 2.8088 - val_loss: 2.8668\n",
            "Epoch 7/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 2.5659\n",
            "Epoch 00007: val_loss improved from 2.86680 to 2.73185, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 289us/sample - loss: 2.5660 - val_loss: 2.7318\n",
            "Epoch 8/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 2.3613\n",
            "Epoch 00008: val_loss improved from 2.73185 to 2.60729, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 290us/sample - loss: 2.3618 - val_loss: 2.6073\n",
            "Epoch 9/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 2.1878\n",
            "Epoch 00009: val_loss improved from 2.60729 to 2.52113, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 288us/sample - loss: 2.1874 - val_loss: 2.5211\n",
            "Epoch 10/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 2.0364\n",
            "Epoch 00010: val_loss improved from 2.52113 to 2.45515, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 289us/sample - loss: 2.0364 - val_loss: 2.4551\n",
            "Epoch 11/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 1.8985\n",
            "Epoch 00011: val_loss improved from 2.45515 to 2.41402, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 288us/sample - loss: 1.8984 - val_loss: 2.4140\n",
            "Epoch 12/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 1.7731\n",
            "Epoch 00012: val_loss improved from 2.41402 to 2.38144, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 38s 287us/sample - loss: 1.7729 - val_loss: 2.3814\n",
            "Epoch 13/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 1.6575\n",
            "Epoch 00013: val_loss did not improve from 2.38144\n",
            "130927/130927 [==============================] - 36s 278us/sample - loss: 1.6574 - val_loss: 2.3915\n",
            "Epoch 14/30\n",
            "130560/130927 [============================>.] - ETA: 0s - loss: 1.5490\n",
            "Epoch 00014: val_loss improved from 2.38144 to 2.35117, saving model to model.h1.09_02_19.h5\n",
            "130927/130927 [==============================] - 37s 285us/sample - loss: 1.5489 - val_loss: 2.3512\n",
            "Epoch 15/30\n",
            " 68096/130927 [==============>...............] - ETA: 16s - loss: 1.4221"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fYynd9TMSiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFPpadFxMhs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model.h1.09_02_19.h5')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX0N-X9cMoJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == n:\n",
        "      return word\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPt5EHqjMrs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = []\n",
        "for i in preds:\n",
        "  temp = []\n",
        "  for j in range(len(i)):\n",
        "    t = get_word(i[j], eng_tokenizer)\n",
        "    if j > 0:\n",
        "      if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "        temp.append('')\n",
        "      else:\n",
        "        temp.append(t)\n",
        "    else:\n",
        "      if(t == None):\n",
        "        temp.append('')\n",
        "      else:\n",
        "        temp.append(t) \n",
        "\n",
        "  preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogx2ZxtM7Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D3wmgSZM9YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print 15 rows randomly\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}